{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Driving Car Nanodegree\n",
    "### Project 3 - Advanced Lane Finding Project\n",
    "The goals/steps of this project are the following: \n",
    "1. Distortion correction using images of chessboards.\n",
    "2. Perspective transformation to view lane lines from straight above.\n",
    "3. Processing images to highlight lanelines.\n",
    "4. Sliding window search to detect lane lines and their curvatures.\n",
    "5. Drawing the detected lane lines on the original images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Distortion correction\n",
    "Images taken from camera have distortions, which occur while putting the 3-D world into a 2-D plane. The distortions are properties of camera lenses. For this reason, once the parameters for the distortion are determined, the images can easily be \"undistorted\".  \n",
    "This undistortion process will be conducted in two steps:  \n",
    "First, distortion parameters will be determined from images of chessboards.   \n",
    "Second, the distortion parameters will be used to undistort images taken from the camera. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.1 - Images of chessboards will be loaded and processed to obtain necessary parameters for undistorting image **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "print('Chessboard process completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.2 - Now that necessary parameters to undistort images are obtained, a function to undistort images from the camera is defined **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image has to be in RGB\n",
    "def undistort(image):\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "print('undistort() function loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.3 - ** Test `undistort()` with a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test undistort()\n",
    "# load image\n",
    "test_images_dir = glob.glob('./test_images/*.jpg')\n",
    "rand_idx = np.random.randint(0, len(test_images_dir)-1)\n",
    "test_image = cv2.imread(test_images_dir[rand_idx])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "# undistort\n",
    "undist = undistort(test_image)\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "plt.subplot(121)\n",
    "plt.imshow(test_image)\n",
    "plt.title('Distorted Image', fontsize = 50)\n",
    "plt.subplot(122)\n",
    "plt.imshow(undist)\n",
    "plt.title('Undistorted Image', fontsize = 50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Perspective Transformation\n",
    "Image captured from a front-facing camera mounted on a vehicle cannot be used for the curvature of the lane lines cannot be measured accurately. Perspective transformation will allow the image to be view from the above straight down, so that the curvatures become more apparent.  \n",
    "This is conducted in two steps:  \n",
    "First, a sample image with lane lines will be used to sample four points, that should form a rectangle when viewed from the above.   \n",
    "Second, the four points will be transformed into a rectangle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1 - Obtain four points from an image **  \n",
    "Using a trial and error method, I found out four points that closely follow the lane lines. In order to find out left and right x coordinates for a given y value, I defined a `x_coord_generator()` function. This takes a single y coordinate, plug it in the two linear functions that follow the lane lines, and return two x coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will load a clean image of road tofind best-fit a trapezoid\n",
    "test_images = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "clean_image = test_images[1]\n",
    "clean_road_image = cv2.imread(clean_image)\n",
    "clean_road_image = cv2.cvtColor(clean_road_image, cv2.COLOR_BGR2RGB)\n",
    "clean_road_image_draw = np.copy(clean_road_image)\n",
    "\n",
    "# Read from the image approximate coordinates\n",
    "# x_bottom_left = 215\n",
    "# x_bottom_right = 1115\n",
    "# x_top_left = 525\n",
    "# x_top_right = 771\n",
    "# y_top = 500\n",
    "# y_bottom = 720\n",
    "\n",
    "def x_coord_generator(y_coord):\n",
    "    # two linear functions are generated with the above points\n",
    "    x_top_left = 27050/22 -31*y_coord/22\n",
    "    x_top_right = 69*y_coord/44 - 620/44\n",
    "    \n",
    "    return x_top_left, x_top_right\n",
    "\n",
    "# x coordinates are calculated for two upper and lower y values\n",
    "y_top = 480\n",
    "x_top_left, x_top_right = x_coord_generator(y_top)\n",
    "y_bottom = 670\n",
    "x_bottom_left, x_bottom_right = x_coord_generator(y_bottom)\n",
    "\n",
    "coords = np.array([[x_bottom_left,y_bottom],[x_top_left,y_top],\n",
    "                   [x_top_right,y_top],[x_bottom_right,y_bottom]], np.int32)\n",
    "coords = coords.reshape((-1,1,2))\n",
    "clean_road_image_draw = cv2.polylines(clean_road_image_draw, [coords], True, (255, 0, 255), 3)\n",
    "\n",
    "imgplot = plt.imshow(clean_road_image_draw)\n",
    "plt.title('image with trapezoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 - Function to undergo perspective transformation  \n",
    "Now that we have figured out four points that closely parallel lane lines, a function to undergo perspective transformation will be constructed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to do perspective transformation\n",
    "src = np.float32([[x_bottom_left,y_bottom],[x_top_left,y_top],\n",
    "                   [x_top_right,y_top],[x_bottom_right,y_bottom]])\n",
    "offset = 250 \n",
    "img_size = (clean_road_image.shape[1], clean_road_image.shape[0])\n",
    "dst = np.float32([[offset, img_size[1]], [offset, offset],\n",
    "                  [img_size[0]-offset, offset],\n",
    "                  [img_size[0]-offset, img_size[1]]])\n",
    "dst_draw = np.array([[offset, img_size[1]-offset], [offset, offset],\n",
    "                  [img_size[0]-offset, offset],\n",
    "                  [img_size[0]-offset, img_size[1]-offset]], np.int32)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "def persp_transform(image):\n",
    "    warped = cv2.warpPerspective(image, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "print('Perspective Transformation Function loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 - Test perspective trasnformation with a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = persp_transform(clean_road_image)\n",
    "dst_draw = dst_draw.reshape((-1,1,2))\n",
    "cv2.line(warped, (offset, img_size[1]), (offset, 0), (255, 0, 255), 10)\n",
    "cv2.line(warped, (img_size[0]-offset, img_size[1]), (img_size[0]-offset, 0), (255, 0, 255), 10)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "plt.subplot(121)\n",
    "plt.imshow(clean_road_image)\n",
    "plt.title('Original Image', fontsize = 50)\n",
    "plt.subplot(122)\n",
    "plt.imshow(warped, cmap='gray')\n",
    "plt.title('Thresholded Gradient', fontsize = 50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Lane Line extraction using Sobel and Color Space\n",
    "`abs_sobel_thresh()`, `mag_thresh()`, `dir_thresh()`, and color spaces will be used to further process images and highlight lane lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 - Sobel operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=6, thresh_max=100):\n",
    "    # Grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply cv2.Sobel()\n",
    "    \n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1)\n",
    "        \n",
    "    # Take the absolute value of the output from cv2.Sobel()\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # Scale the result to an 8-bit range (0-255)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    # Apply lower and upper thresholds\n",
    "    thresh_min = thresh_min\n",
    "    thresh_max = thresh_max\n",
    "    \n",
    "    # Create binary output\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    return binary_output\n",
    "\n",
    "print('abs_sobel_thresh loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(test_images_dir)-1)\n",
    "test_image = cv2.imread(test_images_dir[rand_idx])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "grad_binary = abs_sobel_thresh(test_image, orient='x', thresh_min=6, thresh_max=100)\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "plt.subplot(121)\n",
    "plt.imshow(test_image)\n",
    "plt.title('Original Image', fontsize = 50)\n",
    "plt.subplot(122)\n",
    "plt.imshow(grad_binary, cmap='gray')\n",
    "plt.title('Thresholded Gradient', fontsize = 50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - Magnitude of Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magnitude of gradient \n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to Grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # take the gradient in x and y separately\n",
    "    sobelX = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobelY = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate magnitude\n",
    "    gradmag = np.sqrt(sobelX**2 + sobelY**2)\n",
    "    # Scale to 8-bit (0-255) and convert to type = np.uint8\n",
    "    scale_factor = np.max(gradmag)/255\n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "    # Create a binary mask where mag threshold are met\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag>=mag_thresh[0]) & (gradmag<=mag_thresh[1])] = 1\n",
    "    # Return this mask as binary_output image\n",
    "    return binary_output\n",
    "\n",
    "print('mag_thresh loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(test_images_dir)-1)\n",
    "test_image = cv2.imread(test_images_dir[rand_idx])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mag_binary = mag_thresh(test_image, sobel_kernel=3, mag_thresh=(30,100))\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(mag_binary, cmap='gray')\n",
    "ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - Gradient Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dirction of gradient \n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take a gradient in x and y separately\n",
    "    sobelX = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobelY = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the x an dy gradient\n",
    "    absgraddir = np.arctan2(np.absolute(sobelY), np.absolute(sobelX))\n",
    "    # Use np.arctan2 to calculate the direction of the gradients\n",
    "    binary_output = np.zeros_like(absgraddir)\n",
    "    # Return this mask as binary_output image\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Test with Sample Image **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(test_images_dir)-1)\n",
    "test_image = cv2.imread(test_images_dir[rand_idx])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "dir_binary = dir_threshold(test_image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(dir_binary, cmap='gray')\n",
    "ax2.set_title('Thresholded Grad. Dir.', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 - HLS Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hls_select(img, thresh=(0,255)):\n",
    "    # Convert to HLS color space\n",
    "    img_hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # Apply a threshold to the S channel\n",
    "    s_channel = img_hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel >= thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    # Return a binary image of threshold result\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(test_images_dir)-1)\n",
    "test_image = cv2.imread(test_images_dir[rand_idx])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "hls_binary = hls_select(test_image, thresh=(85, 255))\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(hls_binary, cmap='gray')\n",
    "ax2.set_title('Thresholded S', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Final Pipeline using all above methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Sobel X\n",
    "    sobelX = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0)\n",
    "    abs_sobelX = np.absolute(sobelX)\n",
    "    scaled_sobel = np.uint8(255*abs_sobelX/np.max(abs_sobelX))\n",
    "    \n",
    "    # Threshold x gradient \n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack((np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    \n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    \n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Try out with a sample image **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(test_images_dir)-1)\n",
    "test_image = cv2.imread(test_images_dir[rand_idx])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "binary = pipeline(test_image)\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_image)\n",
    "ax1.set_title('Original Image', fontsize=40)\n",
    "ax2.imshow(binary, cmap='gray')\n",
    "ax2.set_title('Pipeline Result in Gray', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Sliding Window Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_sliding_win(image):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(image[np.int(image.shape[0]/2):,:], axis=0)\n",
    "    # Create an output image to draw on & visualize the result\n",
    "    out_img = np.dstack((image, image, image))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(image.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = image.nonzero()\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    # Current position to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the window +/- margin\n",
    "    margin = 80\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = image.shape[0] - (window+1)*window_height\n",
    "        win_y_high = image.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "            \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Plot results\n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]    \n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    return out_img, left_fitx, right_fitx, ploty\n",
    "\n",
    "print('function loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Test with sample image **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(test_images_dir)-1)\n",
    "test_image = cv2.imread(test_images_dir[rand_idx])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot the results\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "# First need to process image before feeding\n",
    "undist = undistort(test_image)\n",
    "ax1.imshow(undist)\n",
    "ax1.set_title('Undistorted', fontsize=40)\n",
    "\n",
    "binary = pipeline(undist)\n",
    "ax2.imshow(binary)\n",
    "ax2.set_title('Binary', fontsize=40)\n",
    "\n",
    "binary_warped = persp_transform(binary)\n",
    "ax3.imshow(binary_warped)\n",
    "ax3.set_title('Warped', fontsize=40)\n",
    "\n",
    "result, left_fitx, right_fitx, ploty = hist_sliding_win(binary_warped)\n",
    "ax4.imshow(result)\n",
    "ax4.set_title('Sliding Window', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Sliding Window Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_width = 50\n",
    "window_height = 80\n",
    "# NOTE: margin \n",
    "margin = 70 # How much to slide left or right for search \n",
    "\n",
    "# level - row?\n",
    "def window_mask(width, height, draw_on_image, center, level):\n",
    "    output = np.zeros_like(draw_on_image)\n",
    "    img_width = draw_on_image.shape[0]\n",
    "    img_height = draw_on_image.shape[1]\n",
    "    output[int(img_width-(level+1)*height):int(img_width-level*height),\n",
    "           max(0,int(center-width/2)):min(int(center+width/2),img_height)] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(warped, window_width=50, window_height=80, margin=50):\n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(warped.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(warped.shape[0]/window_height)):\n",
    "\t    # convolve the window into the vertical slice of the image\n",
    "\t    image_layer = np.sum(warped[int(warped.shape[0]-(level+1)*window_height):int(warped.shape[0]-level*window_height),:], axis=0)\n",
    "\t    conv_signal = np.convolve(window, image_layer)\n",
    "\t    # Find the best left centroid by using past left center as a reference\n",
    "\t    # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "\t    offset = window_width/2\n",
    "\t    l_min_index = int(max(l_center+offset-margin,0))\n",
    "\t    l_max_index = int(min(l_center+offset+margin,warped.shape[1]))\n",
    "\t    l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "\t    # Find the best right centroid by using past right center as a reference\n",
    "\t    r_min_index = int(max(r_center+offset-margin,0))\n",
    "\t    r_max_index = int(min(r_center+offset+margin,warped.shape[1]))\n",
    "\t    r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "\t    # Add what we found for that layer\n",
    "\t    window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "# level - row?\n",
    "def window_mask(width, height, draw_on_image, center, level):\n",
    "    output = np.zeros_like(draw_on_image)\n",
    "    output[int(draw_on_image.shape[0]-(level+1)*height):int(draw_on_image.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),draw_on_image.shape[1])] = 1\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliding_window2(warped):\n",
    "    window_centroids = find_window_centroids(warped, window_width=50, \n",
    "                                             window_height=80, margin=70)\n",
    "    if len(window_centroids) > 0:\n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(warped)\n",
    "        r_points = np.zeros_like(warped)\n",
    "\n",
    "        # Go through each level and draw the windows \t\n",
    "        for level in range(0,len(window_centroids)):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            # l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "\n",
    "            l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "            r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "            l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "            r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "        template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "        output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "\n",
    "        # If no window centers found, just display orginal road image\n",
    "        y_val = [int(warped.shape[0]-(level+1)*window_height) for level in range(9)]\n",
    "        y_val = y_val[::-1]\n",
    "        x_left = [int(window_centroids[i][0]) for i in range(9)]\n",
    "        x_right = [int(window_centroids[i][1]) for i in range(9)]\n",
    "        left_fit = np.polyfit(y_val, x_left, 2)\n",
    "        right_fit = np.polyfit(y_val, x_right, 2)\n",
    "        ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0])\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    else:\n",
    "        output = np.array(cv2.merge((warped,warped,warped)),np.uint8)\n",
    "\n",
    "    \n",
    "#     Display the final results\n",
    "#     plt.imshow(output)\n",
    "#     plt.plot(left_fitx, ploty[::-1], color='yellow')\n",
    "#     plt.plot(right_fitx, ploty[::-1], color='red')\n",
    "#     plt.title('window fitting results')\n",
    "#     plt.xlim(0, 1280)\n",
    "#     plt.ylim(720, 0)\n",
    "#     plt.show()\n",
    "\n",
    "    # PRINT OUT IN METERS\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "\n",
    "    left_fit_cr = np.polyfit(np.multiply(y_val, ym_per_pix), np.multiply(x_left, xm_per_pix), 2)\n",
    "    right_fit_cr = np.polyfit(np.multiply(y_val, ym_per_pix), np.multiply(x_right, xm_per_pix), 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    left_curverad = np.round(left_curverad, 2)\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    right_curverad = np.round(right_curverad, 2)\n",
    "    # Now our radius of curvature is in meters\n",
    "    print('Left Curvature: {} m | Right Curvature: {} m'.format(left_curverad, right_curverad))\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty[::-1], (left_curverad+right_curverad)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drawing back \n",
    "def draw_to_original(warped, undist, image, left_fitx, right_fitx, ploty):\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "#     plt.imshow(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a class to do sanity check of the car iamge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "        \n",
    "# How?\n",
    "# for n numbers. \n",
    "# if less than n, \n",
    "# sanity check only with radius_of_curvature, others. \n",
    "def check(new_radius_of_curvature, line_inst):\n",
    "    thresh = 0.3\n",
    "    if (new_radius_of_curvature < line_inst.radius_of_curvature*(1+thresh) and \n",
    "        new_radius_of_curvature > line_inst.radius_of_curvature*(1-thresh)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def sanity_check_n_draw(binary_warped, undist, line_instance, image, curvature, left_fitx, right_fitx, ploty, num_recent=12):\n",
    "    # For the first n images, accumulate data\n",
    "    \n",
    "    if (len(line_instance.recent_xfitted) < num_recent):\n",
    "        line_instance.recent_xfitted.extend([left_fitx, right_fitx])\n",
    "        line_instance.radius_of_curvature = curvature\n",
    "        result = draw_to_original(binary_warped, undist, image, left_fitx, right_fitx, ploty)\n",
    "    else:\n",
    "        \n",
    "        if check(curvature, line_instance):\n",
    "            line_instance.recent_xfitted.pop(0)\n",
    "            line_instance.recent_xfitted.pop(0)\n",
    "\n",
    "            line_instance.recent_xfitted.extend([left_fitx, right_fitx])\n",
    "            \n",
    "            # Finding the average best fit of the recent x\n",
    "            x_fitted = line_instance.recent_xfitted\n",
    "            x_left = [line_instance.recent_xfitted[i] for i in range(0, len(line_instance.recent_xfitted), 2)]\n",
    "            x_right = [line_instance.recent_xfitted[i] for i in range(0, len(line_instance.recent_xfitted), 2)]\n",
    "            left_mat = np.zeros_like(x_left[0])\n",
    "            right_mat = np.zeros_like(x_right[0])\n",
    "            \n",
    "            for i in range(len(x_left)):\n",
    "                left_mat = np.add(left_mat, x_left[i])\n",
    "                right_mat = np.add(right_mat, x_right[i])\n",
    "                            \n",
    "            left_avg_mat = np.divide(left_mat, len(x_left))\n",
    "            right_avg_mat = np.divide(right_mat, len(x_right))\n",
    "            \n",
    "            line_instance.bestx = [left_avg_mat, right_avg_mat]\n",
    "            line_instance.radius_of_curvature = curvature\n",
    "            result = draw_to_original(binary_warped, undist, image, left_avg_mat, right_avg_mat, ploty)\n",
    "            line_instance.detected = True\n",
    "            \n",
    "        else:\n",
    "                        \n",
    "            # Finding the average best fit of the recent x\n",
    "            x_fitted = line_instance.recent_xfitted\n",
    "            x_left = [line_instance.recent_xfitted[i] for i in range(0, len(line_instance.recent_xfitted), 2)]\n",
    "            x_right = [line_instance.recent_xfitted[i] for i in range(1, len(line_instance.recent_xfitted), 2)]\n",
    "            left_mat = np.zeros_like(x_left[0])\n",
    "            right_mat = np.zeros_like(x_right[0])\n",
    "            \n",
    "            for i in range(0,len(x_left)):\n",
    "                left_mat = np.add(left_mat, x_left[i])\n",
    "                right_mat = np.add(right_mat, x_right[i])\n",
    "                \n",
    "            left_avg_mat = np.divide(left_mat, len(x_left))\n",
    "            right_avg_mat = np.divide(right_mat, len(x_right))\n",
    "            \n",
    "            line_instance.bestx = [left_avg_mat, right_avg_mat]\n",
    "            # hi\n",
    "            result = draw_to_original(binary_warped, undist, image, left_avg_mat, right_avg_mat, ploty)\n",
    "            line_instance.detected = False\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete pipeline from raw image to image with mask showing detected lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_test = Line()\n",
    "def complete_pipeline(image, line_instance=default_test):    \n",
    "    # 1 - Undistort image \n",
    "    undist = undistort(image)\n",
    "    # 2 - Binary\n",
    "    binary = pipeline(undist)\n",
    "    # 3 - Perspective Transformation\n",
    "    binary_warped = persp_transform(binary)\n",
    "    # 4 - Use sliding window\n",
    "    #  left, right, ploty = sliding_window2(binary_warped)\n",
    "    left, right, ploty, curvature = sliding_window2(binary_warped)\n",
    "\n",
    "    # 5 - Draw back to original image\n",
    "    # if: lane line looks good, plot with the new data\n",
    "    # else: plot with the previous data\n",
    "    # ** Since the images are nearly identical frame by frame, taking average of \n",
    "    # the most recent 5 will be fine. \n",
    "    result = sanity_check_n_draw(binary_warped, undist, line_instance, image, curvature, left, right, ploty)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample image\n",
    "rand_idx = np.random.randint(0, len(test_images_dir)-1)\n",
    "test_image = cv2.imread(test_images_dir[rand_idx])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "check_test = Line()\n",
    "complete_pipeline(test_image, check_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's apply the pipeline to a video clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Import everything needed to edit/save/watch video clips\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = './test_video_output/TestOutput.mp4'\n",
    "clip2 = VideoFileClip('./project_video.mp4')\n",
    "test_clip = clip2.fl_image(complete_pipeline)\n",
    "%time test_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(default_test.recent_xfitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
